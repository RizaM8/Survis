define({ entries : {
    "ChronoRoot": {
        "abstract": "\"{Deep learning methods have outperformed previous techniques in most computer vision tasks, including image-based plant phenotyping. However, massive data collection of root traits and the development of associated artificial intelligence approaches have been hampered by the inaccessibility of the rhizosphere. Here we present ChronoRoot, a system that combines 3D-printed open-hardware with deep segmentation networks for high temporal resolution phenotyping of plant roots in agarized medium.We developed a novel deep learning\u2013based root extraction method that leverages the latest advances in convolutional neural networks for image segmentation and incorporates temporal consistency into the root system architecture reconstruction process. Automatic extraction of phenotypic parameters from sequences of images allowed a comprehensive characterization of the root system growth dynamics. Furthermore, novel time-associated parameters emerged from the analysis of spectral features derived from temporal signals.Our work shows that the combination of machine intelligence methods and a 3D-printed device expands the possibilities of root high-throughput phenotyping for genetics and natural variation studies, as well as the screening of clock-related mutants, revealing novel root traits.}\",",
        "author": "Gaggion, Nicol\u00e1s and Ariel, Federico and Daric, Vladimir and Lambert, \u00c9ric and Legendre, Simon and Roul\u00e9, Thomas and Camoirano, Alejandra and Milone, Diego H and Crespi, Martin and Blein, Thomas and Ferrante, Enzo",
        "doi": "10.1093/gigascience/giab052",
        "eprint": "https://academic.oup.com/gigascience/article-pdf/10/7/giab052/39682870/giab052\\_reviewer\\_3\\_report\\_original\\_submission.pdf",
        "issn": "2047-217X",
        "journal": "GigaScience",
        "keywords": "convolutional neural network, CNN, image segmentation, root system architecture, temporal phenotyping, 3D-printed hardware",
        "month": "07",
        "note": "giab052",
        "number": "7",
        "title": "\"{ChronoRoot: High-throughput phenotyping by deep segmentation networks reveals novel temporal parameters of plant root system architecture}\",",
        "type": "article",
        "url": "https://doi.org/10.1093/gigascience/giab052",
        "volume": "10",
        "year": "2021"
    },
    "MARCUZZO2009785": {
        "abstract": "To obtain development information of individual plant cells, it is necessary to perform in vivo imaging of the specimen under study, through time-lapse confocal microscopy. Automation of cell detection/marking process is important to provide research tools in order to ease the search for special events, such as cell division. In this paper we discuss an automatic cell detection approach for Arabidopsis thaliana based on segmentation, which selects the best cell candidates from a starting watershed-based image segmentation and improves the result by merging adjacent regions. The selection of individual cells is obtained using a support vector machine (SVM) classifier, based on a cell descriptor constructed from the shape and edge strength of the cells\u2019 contour. In addition we proposed a novel cell merging criterion based on edge strength along the line that connects adjacent cells\u2019 centroids, which is a valuable tool in the reduction of cell over-segmentation. The result is largely pruned of badly segmented and over-segmented cells, thus facilitating the study of cells. When comparing the results after merging with the basic watershed segmentation, we obtain 1.5 percent better coverage (increase in F-measure) and up to 27 percent better precision in correct cell segmentation.",
        "author": "Monica Marcuzzo and Pedro Quelhas and Ana Campilho and Ana {Maria Mendon\u00e7a} and Aur\u00e9lio Campilho",
        "doi": "https://doi.org/10.1016/j.compbiomed.2009.06.008",
        "issn": "0010-4825",
        "journal": "Computers in Biology and Medicine",
        "keywords": "Biomedical image processing, Biological cells",
        "number": "9",
        "pages": "785-793",
        "title": "Automated Arabidopsis plant root cell segmentation based on SVM classification and region merging",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0010482509001139",
        "volume": "39",
        "year": "2009"
    },
    "RooTrak": {
        "abstract": "\"{X-ray microcomputed tomography (\u03bcCT) is an invaluable tool for visualizing plant root systems within their natural soil environment noninvasively. However, variations in the x-ray attenuation values of root material and the overlap in attenuation values between roots and soil caused by water and organic materials represent major challenges to data recovery. We report the development of automatic root segmentation methods and software that view \u03bcCT data as a sequence of images through which root objects appear to move as the x-y cross sections are traversed along the z axis of the image stack. Previous approaches have employed significant levels of user interaction and/or fixed criteria to distinguish root and nonroot material. RooTrak exploits multiple, local models of root appearance, each built while tracking a specific segment, to identify new root material. It requires minimal user interaction and is able to adapt to changing root density estimates. The model-guided search for root material arising from the adoption of a visual-tracking framework makes RooTrak less sensitive to the natural ambiguity of x-ray attenuation data. We demonstrate the utility of RooTrak using \u03bcCT scans of maize (Zea mays), wheat (Triticum aestivum), and tomato (Solanum lycopersicum) grown in a range of contrasting soil textures. Our results demonstrate that RooTrak can successfully extract a range of root architectures from the surrounding soil and promises to facilitate future root phenotyping efforts.}\",",
        "author": "Mairhofer, Stefan and Zappala, Susan and Tracy, Saoirse R. and Sturrock, Craig and Bennett, Malcolm and Mooney, Sacha J. and Pridmore, Tony",
        "doi": "10.1104/pp.111.186221",
        "eprint": "https://academic.oup.com/plphys/article-pdf/158/2/561/37156381/plphys\\_v158\\_2\\_561.pdf",
        "issn": "0032-0889",
        "journal": "Plant Physiology",
        "keywords": "top-down approach, thresholding, three-dimensional, \u00b5CT scans",
        "month": "12",
        "number": "2",
        "pages": "561-569",
        "title": "\"{RooTrak: Automated Recovery of Three-Dimensional Plant Root Architecture in Soil from X-Ray Microcomputed Tomography Images Using Visual Tracking \u00a0}\",",
        "type": "article",
        "url": "https://doi.org/10.1104/pp.111.186221",
        "volume": "158",
        "year": "2011"
    },
    "RootNav2.0": {
        "abstract": "\"{In recent years quantitative analysis of root growth has become increasingly important as a way to explore the influence of abiotic stress such as high temperature and drought on a plant's ability to take up water and nutrients. Segmentation and feature extraction of plant roots from images presents a significant computer vision challenge. Root images contain complicated structures, variations in size, background, occlusion, clutter and variation in lighting conditions. We present a new image analysis approach that provides fully automatic extraction of complex root system architectures from a range of plant species in varied imaging set-ups. Driven by modern deep-learning approaches, RootNav 2.0 replaces previously manual and semi-automatic feature extraction with an extremely deep multi-task convolutional neural network architecture. The network also locates seeds, first order and second order root tips to drive a search algorithm seeking optimal paths throughout the image, extracting accurate architectures without user interaction.We develop and train a novel deep network architecture to explicitly combine local pixel information with global scene information in order to accurately segment small root features across high-resolution images. The proposed method was evaluated on images of wheat (Triticum aestivum L.) from a seedling assay. Compared with semi-automatic analysis via the original RootNav tool, the proposed method demonstrated comparable accuracy, with a 10-fold increase in speed. The network was able to adapt to different plant species via transfer learning, offering similar accuracy when transferred to an Arabidopsis thaliana plate assay. A final instance of transfer learning, to images of Brassica napus from a hydroponic assay, still demonstrated good accuracy despite many fewer training images.We present RootNav 2.0, a new approach to root image analysis driven by a deep neural network. The tool can be adapted to new image domains with a reduced number of images, and offers substantial speed improvements over semi-automatic and manual approaches. The tool outputs root architectures in the widely accepted RSML standard, for which numerous analysis packages exist (http://rootsystemml.github.io/), as well as segmentation masks compatible with other automated measurement tools. The tool will provide researchers with the ability to analyse root systems at larget scales than ever before, at a time when large scale genomic studies have made this more important than ever.}\",",
        "author": "Yasrab, Robail and Atkinson, Jonathan A and Wells, Darren M and French, Andrew P and Pridmore, Tony P and Pound, Michael P",
        "doi": "10.1093/gigascience/giz123",
        "eprint": "https://academic.oup.com/gigascience/article-pdf/8/11/giz123/30489583/giz123\\_supplemental\\_file.pdf",
        "issn": "2047-217X",
        "journal": "GigaScience",
        "keywords": "convolutional neural network, CNN, plant phenotyping, computer vison, encoder-decoder, root system",
        "month": "11",
        "note": "giz123",
        "number": "11",
        "title": "\"{RootNav 2.0: Deep learning for automatic navigation of complex plant root architectures}\",",
        "type": "article",
        "url": "https://doi.org/10.1093/gigascience/giz123",
        "volume": "8",
        "year": "2019"
    },
    "SegRoot": {
        "abstract": "The measurement of root growth over time, without destructive excavation from soil is important to understanding the development of plants, communities and ecosystems. However, analyzing root images from the soil is difficult because the contrast between soil particles and roots often presents challenges to segmenting for root extraction. In this paper, we proposed a fully automated method based on convolutional neural networks, called SegRoot, adapted for segmenting root from complex soil background. Our method eliminates the need for delicate feature designing which requires significant expert knowledge. The trained SegRoot networks learned morphological features with different abstraction levels directly from root images. Thus, the generalization and adaptation of the proposed method was expected across different root images. Using images of soybean roots, high performance of segmentation results were obtained by our benchmark SegRoot with testing dice score of 0.6441 (where 1 is a perfect score). When compared with human traced root lengths, an excellent correlation in root total length estimation was achieved with R2 of 0.9791. We also applied SegRoot to images with entirely different soil type collected from a forest ecosystem. Even without training on those images, a good generalization capability was obtained. Additionally, the impact of network capacity was also studied in order to find a cost-effective network suitable for in field application. We believe this automated segmentation method will revolutionize the measurement of plant roots in soil by dramatically increasing the ability to extract data from minirhizotron images.",
        "author": "Tao Wang and Mina Rostamza and Zhihang Song and Liangju Wang and G. McNickle and Anjali S. Iyer-Pascuzzi and Zhengjun Qiu and Jian Jin",
        "doi": "https://doi.org/10.1016/j.compag.2019.05.017",
        "issn": "0168-1699",
        "journal": "Computers and Electronics in Agriculture",
        "keywords": "Root segmentation, Root length estimation, Convolutional neural networks, Dice score",
        "pages": "845-854",
        "title": "SegRoot: A high throughput segmentation method for root image analysis",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0168169919303874",
        "volume": "162",
        "year": "2019"
    },
    "faRIA": {
        "abstract": "High-throughput root phenotyping in the soil became an indispensable quantitative tool for the assessment of effects of climatic factors and molecular perturbation on plant root morphology, development and function. To efficiently analyse a large amount of structurally complex soil-root images advanced methods for automated image segmentation are required. Due to often unavoidable overlap between the intensity of fore- and background regions simple thresholding methods are, generally, not suitable for the segmentation of root regions. Higher-level cognitive models such as convolutional neural networks (CNN) provide capabilities for segmenting roots from heterogeneous and noisy background structures, however, they require a representative set of manually segmented (ground truth) images. Here, we present a GUI-based tool for fully automated quantitative analysis of root images using a pre-trained CNN model, which relies on an extension of the U-Net architecture. The developed CNN framework was designed to efficiently segment root structures of different size, shape and optical contrast using low budget hardware systems. The CNN model was trained on a set of 6465 masks derived from 182 manually segmented near-infrared (NIR) maize root images. Our experimental results show that the proposed approach achieves a Dice coefficient of 0.87 and outperforms existing tools (e.g., SegRoot) with Dice coefficient of 0.67 by application not only to NIR but also to other imaging modalities and plant species such as barley and arabidopsis soil-root images from LED-rhizotron and UV imaging systems, respectively. In summary, the developed software framework enables users to efficiently analyse soil-root images in an automated manner (i.e. without manual interaction with data and/or parameter tuning) providing quantitative plant scientists with a powerful analytical tool.",
        "author": "Narisetti, Narendra and Henke, Michael and Seiler, Christiane and Junker, Astrid and Ostermann, J{\\\"o}rn and Altmann, Thomas and Gladilin, Evgeny",
        "doi": "10.1038/s41598-021-95480-y",
        "journal": "Scientific Reports",
        "keywords": "CNN, annotated root images, U-Net, endoder-decoder",
        "number": "1",
        "pages": "1-15",
        "publisher": "Springer",
        "title": "Fully-automated root image analysis (faRIA)",
        "type": "article",
        "url": "https://www.nature.com/articles/s41598-021-95480-y",
        "volume": "11",
        "year": "2021"
    },
    "galkovskyi2012gia": {
        "abstract": "Background: Characterizing root system architecture (RSA) is essential to understanding the development and function of vascular plants. Identifying RSA-associated genes also represents an underexplored opportunity for crop improvement. Software tools are needed to accelerate the pace at which quantitative traits of RSA are estimated from images of root networks. Results: We have developed GiA Roots (General Image Analysis of Roots), a semi-automated software tool designed specifically for the high-throughput analysis of root system images. GiA Roots includes user-assisted algorithms to distinguish root from background and a fully automated pipeline that extracts dozens of root system phenotypes. Quantitative information on each phenotype, along with intermediate steps for full reproducibility, is returned to the end-user for downstream analysis. GiA Roots has a GUI front end and a command-line interface for interweaving the software into large-scale workflows. GiA Roots can also be extended to estimate novel phenotypes specified by the end-user. Conclusions: We demonstrate the use of GiA Roots on a set of 2393 images of rice roots representing 12 genotypes from the species Oryza sativa. We validate trait measurements against prior analyses of this image set that demonstrated that RSA traits are likely heritable and associated with genotypic differences. Moreover, we demonstrate that GiA Roots is extensible and an end-user can add functionality so that GiA Roots can estimate novel RSA traits. In summary, we show that the software can function as an efficient tool as part of a workflow to move from large numbers of root images to downstream analysis.",
        "author": "Galkovskyi, Taras and Mileyko, Yuriy and Bucksch, Alexander and Moore, Brad and Symonova, Olga and Price, Charles A and Topp, Christopher N and Iyer-Pascuzzi, Anjali S and Zurek, Paul R and Fang, Suqin and others",
        "doi": "10.1186/1471-2229-12-116",
        "journal": "BMC plant biology",
        "keywords": "high throughput, thresholding, pipeline, GUI",
        "number": "1",
        "pages": "1--12",
        "publisher": "BioMed Central",
        "title": "GiA Roots: software for the high throughput analysis of plant root system architecture",
        "type": "article",
        "url": "https://bmcplantbiol.biomedcentral.com/articles/10.1186/1471-2229-12-116",
        "volume": "12",
        "year": "2012"
    },
    "highthroughput": {
        "abstract": "The Rhizotrons method is an important means of detecting dynamic growth and development phenotypes of plant roots. However, the segmentation of root images is a critical obstacle restricting further development of this method. At present, researchers mostly use direct manual drawings or software-assisted manual drawings to segment root systems for analysis. Root systems can be segmented from root images obtained by the Rhizotrons method, and then, root system lengths and diameters can be obtained with software. This type of image segmentation method is extremely inefficient and very prone to human error. Here, we investigate the effectiveness of an automated image segmentation method based on the DeepLabv3+ convolutional neural network (CNN) architecture to streamline such measurements. We have improved the upsampling portion of the DeepLabv3+ network and validated it using in situ images of cotton roots obtained with a micro root window root system monitoring system. Segmentation performance of the proposed method utilizing WinRHIZO Tron MF analysis was assessed using these images. After 80 epochs of training, the final verification set F1-score, recall, and precision were 0.9773, 0.9847, and 0.9702, respectively. The Spearman rank correlation between the manually obtained Rhizotrons manual segmentation root length and automated root length was 0.9667 (p < 10<sup>\u20138</sup>), with r<sup>2</sup>",
        "author": "Shen, Chen and Liu, Liantao and Zhu, Lingxiao and Kang, Jia and Wang, Nan and Shao, Limin",
        "doi": "10.3389/fpls.2020.576791",
        "issn": "1664-462X",
        "journal": "Frontiers in Plant Science",
        "keywords": "root systems, rhizotrons, convolutional neural network, image segmentation, deep-learning",
        "title": "High-Throughput in situ Root Image Segmentation Based on the Improved DeepLabv3+ Method",
        "type": "article",
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2020.576791",
        "volume": "11",
        "year": "2020"
    },
    "pflugfelder2017non": {
        "abstract": "Background: Root systems are highly plastic and adapt according to their soil environment. Studying the particular influence of soils on root development necessitates the adaptation and evaluation of imaging methods for multiple substrates. Non-invasive 3D root images in soil can be obtained using magnetic resonance imaging (MRI). Not all substrates, however, are suitable for MRI. Using barley as a model plant we investigated the achievable image quality and the suitability for root phenotyping of six commercially available natural soil substrates of commonly occurring soil textures. The results are compared with two artificially composed substrates previously documented for MRI root imaging. Results: In five out of the eight tested substrates, barley lateral roots with diameters below 300 \u00b5m could still be resolved. In two other soils, only the thicker barley seminal roots were detectable. For these two substrates the minimal detectable root diameter was between 400 and 500 \u00b5m. Only one soil did not allow imaging of the roots with MRI. In the artificially composed substrates, soil moisture above 70 percent of the maximal water holding capacity (WHCmax) impeded root imaging. For the natural soil substrates, soil moisture had no effect on MRI root image quality in the investigated range of 50-80 percent WHCmax. Conclusions: Almost all tested natural soil substrates allowed for root imaging using MRI. Half of these substrates resulted in root images comparable to our current lab standard substrate, allowing root detection down to a diameter of 300 \u00b5m. These soils were used as supplied by the vendor and, in particular, removal of ferromagnetic particles was not necessary. With the characterization of different soils, investigations such as trait stability across substrates are now possible using noninvasive MRI.",
        "author": "Pflugfelder, Daniel and Metzner, Ralf and van Dusschoten, Dagmar and Reichel, R{\\\"u}diger and Jahnke, Siegfried and Koller, Robert",
        "doi": "10.1186/s13007-017-0252-9",
        "journal": "Plant Methods",
        "keywords": "3D imaging, MRI, Phenotyping, Root, Soil texture",
        "number": "1",
        "pages": "1--9",
        "publisher": "BioMed Central",
        "title": "Non-invasive imaging of plant roots in different soils using magnetic resonance imaging (MRI)",
        "type": "article",
        "url": "https://plantmethods.biomedcentral.com/articles/10.1186/s13007-017-0252-9",
        "volume": "13",
        "year": "2017"
    },
    "seidenthal2022iterative": {
        "abstract": "Accurate segmentation of root system architecture (RSA) from 2D images is an important step in studying phenotypic traits of root systems. Various approaches to image segmentation exist but many of them are not well suited to the thin and reticulated structures characteristic of root systems. The findings presented here describe an approach to RSA segmentation that takes advantage of the inherent structural properties of the root system, a segmentation network architecture we call ITErRoot. We have also generated a novel 2D root image dataset which utilizes an annotation tool developed for producing high quality ground truth segmentation of root systems. Our approach makes use of an iterative neural network architecture to leverage the thin and highly branched properties of root systems for accurate segmentation. Rigorous analysis of model properties was carried out to obtain a high-quality model for 2D root segmentation. Results show a significant improvement over other recent approaches to root segmentation. Validation results show that the model generalizes to plant species with fine and highly branched RSA\u2019s, and performs particularly well in the presence of non-root objects.",
        "author": "Seidenthal, Kyle and Panjvani, Karim and Chandnani, Rahul and Kochian, Leon and Eramian, Mark",
        "doi": "10.1038/s41598-022-19754-9",
        "journal": "Scientific Reports",
        "keywords": "RSA, image segmentation, annotated root images, iterative",
        "number": "1",
        "pages": "16563",
        "publisher": "Nature Publishing Group UK London",
        "title": "Iterative image segmentation of plant roots for high-throughput phenotyping",
        "type": "article",
        "url": "https://www.nature.com/articles/s41598-022-19754-9",
        "volume": "12",
        "year": "2022"
    }
}});